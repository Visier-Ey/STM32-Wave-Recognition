# train_model.py
import numpy as np
import h5py
import os
from tensorflow.keras.models import load_model, Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, InputLayer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# å¯é…ç½®å‚æ•°
class Config:
    dataset_path = "waveform_dataset.h5"
    model_path = "waveform_cnn_256.h5"
    epochs = 20
    batch_size = 32
    class_names = ["SINE", "TRIANGLE", "FSK", "BPSK"]

def load_data():
    if not os.path.exists(Config.dataset_path):
        raise FileNotFoundError(f"âŒ æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {Config.dataset_path}")

    with h5py.File(Config.dataset_path, 'r') as f:
        X = f['X'][:]
        y = f['y'][:]

    return train_test_split(X, y, test_size=0.2, random_state=42)

def build_model(signal_length, num_classes):
    return Sequential([
        InputLayer(input_shape=(signal_length, 1)),
        Conv1D(8, 5, activation='relu'),  # å‡å°‘æ»¤æ³¢å™¨æ•°é‡å’Œæ ¸å¤§å°
        MaxPooling1D(2),
        Conv1D(16, 5, activation='relu'),  # å‡å°‘æ»¤æ³¢å™¨æ•°é‡å’Œæ ¸å¤§å°
        MaxPooling1D(2),
        Flatten(),
        Dense(16, activation='relu'),      # å‡å°‘å…¨è¿æ¥å±‚å•å…ƒæ•°
        Dense(num_classes, activation='softmax')
    ])

def train_model():
    X_train, X_test, y_train, y_test = load_data()
    signal_length = X_train.shape[1]
    num_classes = y_train.shape[1]

    model = build_model(signal_length, num_classes)
    model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

    print("ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹...")
    history = model.fit(X_train, y_train,
                        epochs=Config.epochs,
                        batch_size=Config.batch_size,
                        validation_data=(X_test, y_test))

    loss, acc = model.evaluate(X_test, y_test)
    print(f"âœ… æµ‹è¯•å‡†ç¡®ç‡: {acc:.4f}")

    model.save(Config.model_path)
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ° {Config.model_path}")
    return history

def evaluate_model():
    """éªŒè¯å·²è®­ç»ƒæ¨¡å‹çš„å‡†ç¡®ç‡å’Œæ··æ·†çŸ©é˜µ"""
    if not os.path.exists(Config.model_path):
        raise FileNotFoundError(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {Config.model_path}")
    
    model = load_model(Config.model_path)
    _, X_test, _, y_test = load_data()

    y_pred = model.predict(X_test)
    y_true_labels = np.argmax(y_test, axis=1)
    y_pred_labels = np.argmax(y_pred, axis=1)

    # æ‰“å°åˆ†ç±»æŠ¥å‘Š
    print("\nğŸ“Š åˆ†ç±»æŠ¥å‘Š:")
    print(classification_report(y_true_labels, y_pred_labels, target_names=Config.class_names))

    # æ··æ·†çŸ©é˜µå¯è§†åŒ–
    cm = confusion_matrix(y_true_labels, y_pred_labels)
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=Config.class_names,
                yticklabels=Config.class_names)
    plt.xlabel("Prediction category")
    plt.ylabel("Real category")
    plt.title("confusion matrix")
    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    # åªè§£å¼€ä½ è¦è¿è¡Œçš„éƒ¨åˆ†
    train_model()
    # evaluate_model()  # å¦‚åªéªŒè¯æ¨¡å‹ï¼Œè¯·æ³¨é‡Šä¸Šè¡Œå¹¶å–æ¶ˆæ­¤è¡Œæ³¨é‡Š
